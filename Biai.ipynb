{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### BIAI PROJECT\n","\n","\n","AUTHORS: Konrad Sygut, Dominik Baryś"]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2023-06-03T00:11:25.181946Z","iopub.status.busy":"2023-06-03T00:11:25.181547Z","iopub.status.idle":"2023-06-03T00:11:30.100320Z","shell.execute_reply":"2023-06-03T00:11:30.099340Z","shell.execute_reply.started":"2023-06-03T00:11:25.181910Z"},"trusted":true},"outputs":[],"source":["import os\n","import glob\n","import matplotlib.pyplot as plt\n","import cv2\n","import random\n","import numpy as np\n","import pickle\n","from mpl_toolkits.axes_grid1 import ImageGrid\n","import tensorflow as tf\n","from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D\n","from tensorflow.keras.applications import InceptionV3\n","from tensorflow.keras.models import Model, Sequential\n","from tensorflow.keras.layers import Input, UpSampling2D, Flatten, BatchNormalization, Dense, Dropout, GlobalAveragePooling2D\n","from keras.optimizers import Adam\n","import time\n","from sklearn.preprocessing import OneHotEncoder\n","from sklearn.model_selection import train_test_split\n","from sklearn.model_selection import StratifiedKFold\n","from tensorflow.keras.applications.inception_v3 import preprocess_input\n","from sklearn import metrics\n","import matplotlib.pyplot as plt"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Getting list of images (excluding some that do not open)"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2023-06-03T00:11:30.102645Z","iopub.status.busy":"2023-06-03T00:11:30.102235Z","iopub.status.idle":"2023-06-03T00:11:30.683029Z","shell.execute_reply":"2023-06-03T00:11:30.682100Z","shell.execute_reply.started":"2023-06-03T00:11:30.102595Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["There are 7384 images.\n"]}],"source":["PATH_TO_IMAGES = '/kaggle/input/cats-and-dogs-breeds-classification-oxford-dataset/images/images'\n","PATH_TO_TRIMAPS = '/kaggle/input/cats-and-dogs-breeds-classification-oxford-dataset/annotations/annotations/trimaps'\n","# setting image pixel side size\n","SIZEOF_IMAGE = 299\n","\n","bad = {'Abyssinian_34.jpg', 'Egyptian_Mau_145.jpg', 'Egyptian_Mau_139.jpg', 'Egyptian_Mau_191.jpg', 'Egyptian_Mau_177.jpg', 'Egyptian_Mau_167.jpg'}\n","\n","all_imgs = [i for i in os.listdir(PATH_TO_IMAGES) if i.rsplit('.',1)[1] == 'jpg' and i not in bad]\n","all_trimaps = [i for i in os.listdir(PATH_TO_TRIMAPS) if i.rsplit('.',1)[1] == 'png']\n","\n","print('There are ' + str(len(all_imgs)) + ' images.')\n"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2023-06-03T00:11:30.684839Z","iopub.status.busy":"2023-06-03T00:11:30.684439Z","iopub.status.idle":"2023-06-03T00:11:30.728585Z","shell.execute_reply":"2023-06-03T00:11:30.727602Z","shell.execute_reply.started":"2023-06-03T00:11:30.684807Z"},"trusted":true},"outputs":[],"source":["# getting info from 'list.txt' file\n","l = open('/kaggle/input/cats-and-dogs-breeds-classification-oxford-dataset/annotations/annotations/list.txt', 'r')\n","get_breed = lambda pic : pic.rsplit('_',1)[0].lower()\n","get_species = lambda num : 'cat' if num==1 else 'dog'\n","\n","info_by_id = {}\n","info_by_breed = {}\n","\n","# taking note of the names and ids of the breeds\n","for line in l:\n","  if line[0] == '#':\n","    continue\n","  line = line.strip().split(' ')\n","  species = get_species(int(line[2]))\n","  id = int(line[1])\n","  breedid = int(line[3])\n","  name = get_breed(line[0]).lower()\n","  if name not in info_by_breed:\n","    info_by_breed[name] = {'breed' : name, 'species' : species, 'globalid': id, 'breedid':breedid, 'count':0}\n","    info_by_id[id] = info_by_breed[name]\n","\n","# to count the images we can't trust the file\n","for p in [get_breed(n) for n in all_imgs]:\n","  info_by_breed[p]['count']+=1\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### To get information about the images from the `list.txt` file\n","Information is extracted into 2 dictionaries: `info_by_id` and `info_by_breed`"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2023-06-03T00:11:30.730281Z"},"trusted":true},"outputs":[],"source":["ids = list(info_by_id.keys())\n","\n","# X value:\n","counts = [info_by_id[id]['count'] for id in ids]\n","x_labels = [info_by_id[i]['breed'] for i in ids]\n","\n","# Colours & legend:\n","colours = [ 'green' if info_by_id[id]['species']=='cat' else 'purple' for id in ids]\n","\n","colours_leg = {'cat': 'green', 'dog':'purple'}\n","labels = list(colours_leg.keys())\n","handles = [plt.Rectangle((0,0),1,1, color=colours_leg[label]) for label in colours_leg]\n","\n","# Plotting:\n","fig, ax = plt.subplots( figsize= (11,9))\n","ax.barh(ids, counts, color=colours) # barh instead of bar\n","\n","# Set ticks & axis labels & legend:\n","ax.set_yticks(ids) # set_yticks instead of set_xticks\n","ax.set_yticklabels(x_labels) # set_yticklabels instead of set_xticklabels\n","plt.legend(handles, labels)\n","plt.ylabel('Cats and dogs breeds') # swapped places\n","plt.xlabel('Amount of pictures') # swapped places\n","plt.title('Division of cats and dogs by breed')\n","\n","# Set X axis limit:\n","plt.xlim(0, 225)\n","\n","plt.savefig('wykres.png', bbox_inches='tight')\n","\n","plt.show()\n","\n","nr_cats = sum([ info_by_id[id]['count'] for id in ids if info_by_id[id]['species'] == 'cat' ])\n","nr_dogs = sum([ info_by_id[id]['count'] for id in ids if info_by_id[id]['species'] == 'dog' ])\n","\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Display a bar chart of the number of images per breed & couting images per species"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### _Reading_ all images, resizing and adding to list"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def getXy(imgs=None):\n","  # function that returns the number correspondent to the breed of   the animal in the image, given the image name\n","  get_class_no = lambda name : info_by_breed[get_breed(name)]  ['globalid']\n","  \n","  # this set was only used in the begining, before knowing which   images were not opening\n","  # bad = set()\n","  \n","  # all image tensors will be stored here after resizing\n","  training_data = []\n","  \n","  for img in all_imgs:\n","    path = os.path.join(PATH_TO_IMAGES, img)\n","  \n","    # this is a trick to make the image be opened in RGB format,   which is not the default\n","    img_array = cv2.imread(path)[...,::-1] \n","  \n","    # this next block of code, just like the 'bad' set, was   used before finding out \"bad\" images\n","    # if img_array is None:\n","    #   bad.add(img)\n","    #   continue\n","  \n","\n","    # here the images are rezise\n","    img_array = cv2.resize(img_array, (SIZEOF_IMAGE, SIZEOF_IMAGE))\n","  \n","    # get the ID of the image class\n","    class_no = get_class_no(img)\n","  \n","    if imgs is not None and class_no not in imgs:\n","      imgs[class_no] = path\n","  \n","    training_data.append([img_array, class_no])\n","    \n","  # data should be in random order to improve performance\n","  random.shuffle(training_data)\n","  \n","  # separating data from list\n","  training = list(zip(*training_data))\n","  X = training[0]\n","  y = training[1]\n","  \n","  # transforming X to an np.array and resizing\n","  X = np.array(X).reshape(-1, SIZEOF_IMAGE, SIZEOF_IMAGE, 3)\n","  return X, y\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Saving this data to files to make it easier to use it"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def save(obj, fic_name, open_type='wb'):\n","  pickle_out = open(fic_name, open_type)\n","  pickle.dump(obj, pickle_out)\n","  pickle_out.close()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# this is a dictionary that is going to be used to map the ID to a   path to an image, with the same goal as the list before\n","imgs = {}\n","\n","X, y = getXy(imgs=imgs)\n","save(X, 'X299.pickle')\n","save(y, 'y299.pickle')\n","print(X.shape)\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Display a chart containing one image per breed in the data set"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# getting a list of all images we want to show in order\n","ids = list(imgs.keys())\n","figs = [cv2.resize(cv2.imread(imgs[i])[...,::-1], (SIZEOF_IMAGE, SIZEOF_IMAGE)) for i in ids]\n","\n","fig = plt.figure(figsize=(50,50))\n","grid = ImageGrid(\n","    fig,\n","    111,\n","    nrows_ncols=(6, 6),\n","    axes_pad=0.5\n",")\n","\n","i = 1\n","for ax, im in zip(grid, figs):\n","    # putting the correspondent number at the top:\n","    breed_name = info_by_id[ids[i-1]]['breed']  # Pobranie nazwy rasy dla danego numeru\n","    ax.set_title(f\"{i}: {breed_name}\", loc='center', fontsize=32)  # Dodanie nazwy rasy do tytułu\n","    ax.imshow(im)\n","    ax.axis('off')\n","    i+=1\n","\n","fig.subplots_adjust(top=1.27)\n","fig.suptitle('Examples of Pet Image per Breed', size='large')\n","plt.savefig('nazwa_pliku.png', bbox_inches='tight')\n","plt.show()\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Loading files"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["X = pickle.load(open(\"X299.pickle\",\"rb\"))\n","X = np.array(X)\n","\n","y = pickle.load(open(\"y299.pickle\",\"rb\"))\n","y = np.array(y)\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Split data into training and testing data\n","This split is stratified, which means that the ratios between the numbers of images in each class will be kept equal in the testing set"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Function that returns the (complex) model according to some variables"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def getModel(dropout=.25, learning_rate=0.001):\n","  base_model = InceptionV3(weights='imagenet', include_top=False, input_shape=(299, 299, 3))\n","  base_model.trainable = False\n","\n","  inputs = tf.keras.Input(shape=(299, 299, 3))\n","  x = inputs\n","  x = tf.keras.applications.inception_v3.preprocess_input(x)\n","  x = base_model(x, training=False)\n","  x = tf.keras.layers.GlobalAveragePooling2D()(x)\n","  x = tf.keras.layers.Dense(256,activation='relu')(x)\n","  x = tf.keras.layers.Dropout(dropout)(x)\n","  x = tf.keras.layers.BatchNormalization()(x)\n","  outputs = tf.keras.layers.Dense(37,activation='softmax')(x)\n","  model = tf.keras.Model(inputs, outputs)\n","  model.summary()\n","\n","  model.compile(loss='categorical_crossentropy', optimizer=Adam(learning_rate=learning_rate), metrics=['accuracy'])\n","\n","  return model"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Function to encode `y` to arrays of 0's and 1's so it checks out with the model we have"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["onehot_encoder = OneHotEncoder(sparse=False)\n","def onehotencode_func(y):\n","  integer_encoded = y.reshape(len(y), 1)\n","  onehot_encoded = onehot_encoder.fit_transform(integer_encoded)\n","  return onehot_encoded"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Defining values that will be experimented with and setting up k-fold cross validation"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["learning_rate_list = [0.01, 0.001]\n","dropout_values_list = [0.25, 0.35]\n","\n","# 3-fold cross validation will be used because its computationally easier/faster\n","kfold = StratifiedKFold(n_splits=3, shuffle=True)\n","\n","# dictionary where data will be stored\n","hist = {'learning_rate': {}, 'neurons': {}, 'dropout': {}}"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Functions used later to save data from hyper parameter tuning on files, and to read them as well"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def save_in_file(parameter, dict, filename):\n","  f = open(filename, 'ab')\n","  pickle.dump({parameter : dict[parameter]}, f)\n","  f.close()\n","\n","# returns a list\n","def read_file(filename):\n","  objs = [] \n","  f = open(filename, 'rb')\n","  while 1:\n","      try:\n","          objs.append(pickle.load(f))\n","      except EOFError:\n","          break\n","  f.close()\n","  return objs"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Function where information from k-fold cross validation will be averaged, stored and returned"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# the 'model_func' parameter is a lambda function\n","def test_params(lr, model_func):\n","  dic = {}\n","  i = 0.0\n","\n","  # splitting data into the folds\n","  folds = kfold.split(x_train, y_train)\n","  for train_index, val_index in folds:\n","\n","    # getting the model with the desired parameters\n","    model = model_func(lr)\n","\n","    x_train_kf, x_val_kf =  x_train[train_index], x_train[val_index]\n","    y_train_kf, y_val_kf = onehotencode_func(y_train[train_index]), onehotencode_func(y_train[val_index])\n","\n","    # training the model with data from the train data folds\n","    historytemp = model.fit(x_train_kf, y_train_kf, batch_size=32, epochs=15, validation_data=(x_val_kf, y_val_kf))\n","\n","    del model\n","\n","    if dic == {}:\n","      # if dictionary is empty, values will be put there\n","      dic['train_acc'] = np.array(historytemp.history['accuracy'])\n","      dic['train_loss'] = np.array(historytemp.history['loss'])\n","      dic['val_acc'] = np.array(historytemp.history['val_accuracy'])\n","      dic['val_loss'] = np.array(historytemp.history['val_loss'])\n","    else:\n","      # if dictionary is not empty, values will be added element wise\n","      dic['train_acc'] += np.array(historytemp.history['accuracy'])\n","      dic['train_loss'] += np.array(historytemp.history['loss'])\n","      dic['val_acc'] += np.array(historytemp.history['val_accuracy'])\n","      dic['val_loss'] += np.array(historytemp.history['val_loss'])\n","    \n","    i+=1\n","\n","  for k in dic:\n","    # each number in each array in the dictionary will be divided by the number of iterations, producing the mean of all the values read\n","    dic[k] /= i\n","\n","  return dic"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Setting up the experiences"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# changing learning rate:\n","lr_model_func = lambda x : getModel(learning_rate=x)\n","for lr in learning_rate_list:\n","  hist['learning_rate'][lr] = test_params(lr, lr_model_func)\n","\n","save_in_file('learning_rate', hist, 'data299-simple.pickle')\n","\n","\n","# chaning dropout value:\n","drop_model_func = lambda x : getModel(dropout=x)\n","for d in dropout_values_list:\n","  hist['dropout'][d] = test_params(d, drop_model_func)\n","\n","save_in_file('dropout', hist, 'data299-simple.pickle')\n","\n","\n","print(read_file('data299-simple.pickle'))"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Displaying a representation of the neural network architecture"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["m = getModel()"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Displaying the confusion matrix and metrics table\n","Through our analysis, we discovered that the best parameters were:\n","* **learning rate** = 0.001\n","* **dropout value** = 0.35"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["get a new model and train it with all the training data available:"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["model = getModel(learning_rate=0.001, dropout=0.35)\n","model.fit(x_train, onehotencode_func(y_train), batch_size=32, epochs=15)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Getting the predictions of the test data and transforming it to a number (selecting the index of the maximum value and summing one):"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["y_pred = model.predict(x_test)\n","y_pred2 = [ np.argmax(i)+1 for i in y_pred]"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# list of labels in order gotten from the previous notebook\n","labels = ['abyssinian', 'american_bulldog', 'american_pit_bull_terrier', 'basset_hound', 'beagle', 'bengal', 'birman', 'bombay', 'boxer', 'british_shorthair', 'chihuahua', 'egyptian_mau', 'english_cocker_spaniel', 'english_setter', 'german_shorthaired', 'great_pyrenees', 'havanese', 'japanese_chin', 'keeshond', 'leonberger', 'maine_coon', 'miniature_pinscher', 'newfoundland', 'persian', 'pomeranian', 'pug', 'ragdoll', 'russian_blue', 'saint_bernard', 'samoyed', 'scottish_terrier', 'shiba_inu', 'siamese', 'sphynx', 'staffordshire_bull_terrier', 'wheaten_terrier', 'yorkshire_terrier']"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import seaborn as sns\n","import pandas as pd\n","\n","# Tworzenie macierzy pomyłek\n","cm = metrics.confusion_matrix(y_test, y_pred2)\n","\n","cm_df = pd.DataFrame(cm, index=labels, columns=labels)\n","\n","plt.figure(figsize=(12, 12))\n","\n","\n","sns.heatmap(cm_df,fmt='g', cmap='Blues', cbar=False)\n","\n","plt.title('Confusion Matrix', size='xx-large')\n","plt.ylabel('Actual Breed')\n","plt.xlabel('Predicted Breed')\n","\n","plt.xticks(rotation=90)  # Obróć etykiety osi x o 90 stopni\n","plt.savefig('wykres.png', bbox_inches='tight')\n","plt.show()\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Fine-tuning transfer learning model"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["model.compile(loss=tf.keras.losses.CategoricalCrossentropy(),\n","              optimizer = tf.keras.optimizers.RMSprop(lr=0.001/10),\n","              metrics=['accuracy'])"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Function to read pickle files to a list"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def read_file(f):\n","  objs = [] \n","  f = open(f, 'rb')\n","  while 1:\n","      try:\n","          objs.append(pickle.load(f))\n","      except EOFError:\n","          break\n","  f.close()\n","  return objs"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Reading the files with historic information about the hyper parameter tuning\n","The name of the file passed to the `read_file` function should be changed to the correct name of the file"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["l = read_file('data299-simple.pickle')\n","lr = l[-2]['learning_rate']\n","d = l[-1]['dropout']\n","\n","\n","# dictionary that maps the keys of the dictionaries above to the \"normal\" name of the metric\n","metric2name = {'train_acc' : 'train accuracy', 'train_loss' : 'train loss', 'val_acc': 'validation accuracy', 'val_loss': 'validation loss'}"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Displaying charts\n","Evaluating different learning rates:"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["fig, axs = plt.subplots(2, figsize=(15, 15))\n","\n","metric_colors = {\n","    \"train accuracy\": \"orange\",\n","    \"validation accuracy\": \"black\",\n","    \"train loss\": \"darkgreen\",\n","    \"validation loss\": \"darkblue\"\n","}\n","\n","i = 0\n","for idx, val in enumerate(d):\n","    for metric in d[val]:\n","        axs[i].plot(d[val][metric], color=metric_colors[metric2name[metric]], linestyle='solid', label=metric2name[metric])\n","    axs[i].set_title('Drop rate: ' + str(val), fontsize=16)\n","    axs[i].set_xlabel('Epoch Count', fontsize=14)\n","    axs[i].set_ylabel('Metric Value', fontsize=14)\n","    axs[i].legend(loc='upper right')\n","    axs[i].set_facecolor('lightgrey')\n","    axs[i].grid(True)\n","    axs[i].set_ylim([0, 1.2])\n","    i += 1\n","\n","fig.suptitle('Metric Changes over Learning Rates', size='xx-large', y=1.05)\n","fig.tight_layout()\n","plt.savefig('droprate-complex.png', bbox_inches='tight')\n","plt.show()"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Evaluating different dropout values:"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["fig, axs = plt.subplots(2, figsize=(15, 15))\n","\n","metric_colors = {\n","    \"train accuracy\": \"orange\",\n","    \"validation accuracy\": \"black\",\n","    \"train loss\": \"darkgreen\",\n","    \"validation loss\": \"darkblue\"\n","}\n","\n","i = 0\n","for idx, val in enumerate(lr):\n","    for metric in lr[val]:\n","        # Przypisujemy kolor na podstawie nazwy metryki\n","        axs[i].plot(lr[val][metric], color=metric_colors[metric2name[metric]], linestyle='solid', label=metric2name[metric])\n","    axs[i].set_title('Learning Rate: ' + str(val), fontsize=16)\n","    axs[i].set_xlabel('Epoch Count', fontsize=14)\n","    axs[i].set_ylabel('Metric Value', fontsize=14)\n","    axs[i].legend(loc='upper right')\n","    axs[i].set_facecolor('lightgrey')\n","    axs[i].grid(True)\n","\n","    axs[i].set_ylim([0, 1.2])\n","    i += 1\n","\n","fig.suptitle('Metric Changes over Learning Rates', size='xx-large', y=1.05)\n","fig.tight_layout()\n","plt.savefig('learningrate-complex.png', bbox_inches='tight')\n","plt.show()"]}],"metadata":{"interpreter":{"hash":"31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"},"metadata":{"interpreter":{"hash":"31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"}}},"nbformat":4,"nbformat_minor":4}
